{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn, tf-idf 결과 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn tf-idf \n",
    "# 단어 기준 토큰화 (default)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom : {'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n",
      "sklearn : {'and': 0, 'document': 1, 'first': 2, 'is': 3, 'one': 4, 'second': 5, 'the': 6, 'third': 7, 'this': 8}\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(corpus:List[str]):\n",
    "    \"\"\"\n",
    "    단어 오름차순 정렬 vocab\n",
    "    \"\"\"\n",
    "    counter=Counter()\n",
    "    for doc in corpus:\n",
    "        counter.update(re.findall(r'\\w+',doc.lower()))\n",
    "    return { term:idx for idx,term in enumerate(sorted(counter.keys())) }\n",
    "\n",
    "print(f'custom : {build_vocab(corpus)}')\n",
    "print(f'sklearn : {dict(sorted(vectorizer.vocabulary_.items()))}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF  생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def build_tf(terms:List[str],corpus:List[str]):\n",
    "    \"\"\"\n",
    "    각 문서(d) 마다  TF 생성 \n",
    "    \"\"\"\n",
    "    doc_tf=[]\n",
    "    for d in corpus:\n",
    "        tf=[]\n",
    "        for t in terms:\n",
    "            tf.append(\n",
    "                re.findall(r'\\w+',d.lower()).count(t)\n",
    "            )\n",
    "        doc_tf.append(tf)\n",
    "    return np.array(doc_tf)\n",
    "vocab=build_vocab(corpus)\n",
    "print(build_tf(vocab,corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom : [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n",
      "sklearn : [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n"
     ]
    }
   ],
   "source": [
    "def build_df(terms:List[str],corpus:List[str]):\n",
    "    \"\"\"\n",
    "    해당 단어(t) 포함된 문서(d) 의 수 \n",
    "    \"\"\"\n",
    "    df=[]\n",
    "    for t in terms : \n",
    "        count=0\n",
    "        for d in corpus:\n",
    "            if t in re.findall(r'\\w+',d.lower()):\n",
    "                count+=1\n",
    "        df.append(count)\n",
    "    return np.array(df)\n",
    "\n",
    "\n",
    "def build_idf(n:int,df:np.ndarray):\n",
    "    \"\"\"\n",
    "    idf = log((1+n)/(df(t)+1))+1 \n",
    "    \"\"\"\n",
    "    \n",
    "    return np.log((1+n)/(1+df))+1\n",
    "\n",
    "vocab=build_vocab(corpus)\n",
    "df=build_df(vocab.keys(),corpus)\n",
    "n=len(corpus)\n",
    "\n",
    "print(f'custom : {build_idf(n,df)}')\n",
    "print(f'sklearn : {vectorizer.idf_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom : [[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n",
      "sklearn : [[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "def build_tf_idf(tf:np.ndarray,idf:np.ndarray):\n",
    "    return normalize(tf*idf,norm='l2')\n",
    "\n",
    "vocab=build_vocab(corpus)\n",
    "tf=build_tf(vocab,corpus)\n",
    "df=build_df(vocab.keys(),corpus)\n",
    "n=len(corpus)\n",
    "idf=build_idf(n,df)\n",
    "\n",
    "print(f'custom : {build_tf_idf(tf,idf)}')\n",
    "print(f'sklearn : {X.toarray()}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13997ad55eaa4bddd5b901c8c806e60b0c92a0ee636dbe8a12a14ebb7e77368c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('DL-torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
